{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence\n",
    "# 464/664\n",
    "# Assignment #7\n",
    "\n",
    "## General Directions for this Assignment\n",
    "\n",
    "00. We're using a Jupyter Notebook environment (tutorial available here: https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html),\n",
    "01. Output format should be exactly as requested (it is your responsibility to make sure notebook looks as expected on Gradescope),\n",
    "02. Check submission deadline on Gradescope, \n",
    "03. Rename the file to Last_First_assignment_7, \n",
    "04. Submit your notebook (as .ipynb, not PDF) using Gradescope, and\n",
    "05. Do not submit any other files.\n",
    "\n",
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Neural Networks\n",
    "\n",
    "For this assignment we will explore Neural Networks; in particular, we are going to explore model complexity. We will use the same dataset from Assignment #6 to classify a mushroom as either edible ('e') or poisonous ('p'). You are free to use PyTorch, TensorFlow, scikit-learn -- to name a few resources. The goal is to explore different model complexities (architectures) before declaring a winner. Either start with a simple network and make it more complex; or start with a complex model and pare it down. Either way, your submission should clearly demonstrate your exploration. \n",
    "\n",
    "\n",
    "Your output for each model should look like the output of `cross_validate` from Assignment #6:\n",
    "\n",
    "```\n",
    "Fold: 0\tTrain Error: 15.38%\tValidation Error: 0.00%\n",
    "Fold: 1\n",
    "...\n",
    "\n",
    "Mean(Std. Dev.) over all folds:\n",
    "-------------------------------\n",
    "Train Error: 100.00%(0.00%) Test Error: 100.00%(0.00%)\n",
    "```\n",
    "\n",
    "Notice that \"Test Error\" has been replaced by \"Validation Error.\" Split your dataset into train, test, and validation sets. \n",
    "\n",
    "\n",
    "Start with a simple network. Train using the train set. Observe model's performance using the validation set. \n",
    "\n",
    "\n",
    "Increase the complexity of your network. Train using the train set. Observe model's performance using the validation set. \n",
    "\n",
    "\n",
    "Model complexity in Assignment #6 was depth limit. You can think of it here as the architecture of the network (number of layers and units per layer). Try at least three different network architectures. \n",
    "\n",
    "\n",
    "We're trying to find a model complexity that generalizes well. (Recall high bias vs high variance discussion in class.) \n",
    "\n",
    "\n",
    "Pick the network architecture that you deem best. Use the test set to report your winning model's performance. This is the ONLY time you use the test set.\n",
    "\n",
    "\n",
    "No other directions for this assignment, other than what's here and in the \"General Directions\" section. You have a lot of freedom with this assignment. Don't get carried away. Try at least three different models; more importantly, document your process. Graders are not going to run your notebooks. The notebook will be read as a report on how different models were explored: what the results were, how the winning model was determined, what was the winning model's performance on the test data. Clearly highlight these items to receive full credit. Since you'll be using libraries, the emphasis will be on your ability to communicate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 23:00:36.484523: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# pyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0    Validation Error: 66.67%\n",
      "Fold: 1    Validation Error: 33.33%\n",
      "Fold: 2    Validation Error: 33.33%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Validation Error: 44.44% (15.71%)\n",
      "\n",
      "\n",
      "Fold: 0    Validation Error: 66.67%\n",
      "Fold: 1    Validation Error: 33.33%\n",
      "Fold: 2    Validation Error: 33.33%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Validation Error: 44.44% (15.71%)\n",
      "\n",
      "\n",
      "Fold: 0    Validation Error: 33.33%\n",
      "Fold: 1    Validation Error: 0.00%\n",
      "Fold: 2    Validation Error: 33.33%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Validation Error: 22.22% (15.71%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M1: pyTorch\n",
    "# dataset given in assignment #6 \n",
    "data = [['round','large','blue','no'],\n",
    "['square','large','green','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','blue','no'],\n",
    "['round','small','blue','no'],\n",
    "['round','small','red','yes'],\n",
    "['square','small','green','no'],\n",
    "['round','large','green','yes'],\n",
    "['square','large','green','yes'],\n",
    "['square','large','red','no'],\n",
    "['square','large','green','yes'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','small','green','no']]\n",
    "attribute_names = ['shape', 'size', 'color']\n",
    "\n",
    "data = np.array(data)\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# convert categorical features and labels to numerical values\n",
    "shape_map = {'round': 0, 'square': 1}\n",
    "size_map = {'small': 0, 'large': 1}\n",
    "color_map = {'blue': 0, 'green': 1, 'red': 2}\n",
    "label_map = {'no': 0, 'yes': 1}\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    X[i, 0] = shape_map[X[i, 0]]\n",
    "    X[i, 1] = size_map[X[i, 1]]\n",
    "    X[i, 2] = color_map[X[i, 2]]\n",
    "    y[i] = label_map[y[i]]\n",
    "\n",
    "X = X.astype(int)\n",
    "y = y.astype(int)\n",
    "\n",
    "# splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "def create_pytorch_model(input_size, output_size, hidden_layers, units_per_layer, activation):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(input_size, units_per_layer))\n",
    "    layers.append(activation())\n",
    "    \n",
    "    for _ in range(hidden_layers - 1):\n",
    "        layers.append(nn.Linear(units_per_layer, units_per_layer))\n",
    "        layers.append(activation())\n",
    "    layers.append(nn.Linear(units_per_layer, output_size))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def train_pytorch_model(model, criterion, optimizer, X_train, y_train):\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.tensor(X_train, dtype=torch.float32))\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        loss = criterion(outputs.squeeze(), torch.tensor(y_train, dtype=torch.float32))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate_pytorch_model(model, X_val, y_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_val, dtype=torch.float32))\n",
    "        val_preds = (outputs.squeeze() > 0.5).int().numpy()\n",
    "        val_error = 1 - accuracy_score(y_val, val_preds)\n",
    "    return val_error\n",
    "\n",
    "def cross_validate_pytorch(X, y, model_params, n_folds=3):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    for params in model_params:\n",
    "        val_errors = []\n",
    "        for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "            X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "            y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "            model = create_pytorch_model(X.shape[1], 1, **params)\n",
    "            criterion = nn.BCELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            train_pytorch_model(model, criterion, optimizer, X_train_fold, y_train_fold)\n",
    "            val_error = evaluate_pytorch_model(model, X_val_fold, y_val_fold)\n",
    "            val_errors.append(val_error)\n",
    "            print(f\"Fold: {fold}    Validation Error: {val_error*100:.2f}%\")\n",
    "        print(\"\\nMean(Std. Dev.) over all folds:\\n-------------------------------\")\n",
    "        print(f\"Validation Error: {np.mean(val_errors)*100:.2f}% ({np.std(val_errors)*100:.2f}%)\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "model_params = [\n",
    "    {'hidden_layers': 1, 'units_per_layer': 4, 'activation': nn.ReLU}, \n",
    "    {'hidden_layers': 2, 'units_per_layer': 15, 'activation': nn.ReLU},\n",
    "    {'hidden_layers': 3, 'units_per_layer': 36, 'activation': nn.ReLU}\n",
    "]\n",
    "\n",
    "cross_validate_pytorch(X_train, y_train, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Fold: 0    Validation Error: 66.67%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Fold: 1    Validation Error: 33.33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Fold: 2    Validation Error: 33.33%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Validation Error: 44.44% (15.71%)\n",
      "\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Fold: 0    Validation Error: 66.67%\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1748ee200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Fold: 1    Validation Error: 0.00%\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x174e998a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "Fold: 2    Validation Error: 33.33%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Validation Error: 33.33% (27.22%)\n",
      "\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Fold: 0    Validation Error: 66.67%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Fold: 1    Validation Error: 66.67%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Fold: 2    Validation Error: 33.33%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Validation Error: 55.56% (15.71%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M2: tensorflow\n",
    "data = [['round','large','blue','no'],\n",
    "['square','large','green','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','blue','no'],\n",
    "['round','small','blue','no'],\n",
    "['round','small','red','yes'],\n",
    "['square','small','green','no'],\n",
    "['round','large','green','yes'],\n",
    "['square','large','green','yes'],\n",
    "['square','large','red','no'],\n",
    "['square','large','green','yes'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','small','green','no']]\n",
    "\n",
    "attribute_names = ['shape', 'size', 'color', 'label']\n",
    "df = pd.DataFrame(data, columns=attribute_names)\n",
    "\n",
    "# Map categorical features to integers\n",
    "shape_map = {'round': 0, 'square': 1}\n",
    "size_map = {'small': 0, 'large': 1}\n",
    "color_map = {'blue': 0, 'green': 1, 'red': 2}\n",
    "label_map = {'no': 0, 'yes': 1}\n",
    "\n",
    "df['shape'] = df['shape'].map(shape_map)\n",
    "df['size'] = df['size'].map(size_map)\n",
    "df['color'] = df['color'].map(color_map)\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "def create_tf_model_with_embeddings(input_dims, output_shape, hidden_layers, units_per_layer):\n",
    "    input_layers = []\n",
    "    embedding_layers = []\n",
    "    for input_dim in input_dims:\n",
    "        input_layer = tf.keras.layers.Input(shape=(1,))\n",
    "        embedding_layer = tf.keras.layers.Embedding(input_dim, 2)(input_layer)\n",
    "        embedding_layer = tf.keras.layers.Reshape(target_shape=(2,))(embedding_layer)\n",
    "        input_layers.append(input_layer)\n",
    "        embedding_layers.append(embedding_layer)\n",
    "    merged_layer = tf.keras.layers.concatenate(embedding_layers)\n",
    "    for _ in range(hidden_layers):\n",
    "        merged_layer = tf.keras.layers.Dense(units_per_layer, activation='relu')(merged_layer)\n",
    "    output_layer = tf.keras.layers.Dense(output_shape, activation='sigmoid')(merged_layer)\n",
    "    model = tf.keras.Model(inputs=input_layers, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "def train_tf_model_with_embeddings(model, X_train, y_train, X_val, y_val):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit([X_train[col] for col in X_train.columns], y_train, \n",
    "                        validation_data=([X_val[col] for col in X_val.columns], y_val), \n",
    "                        epochs=50, batch_size=8, verbose=0)\n",
    "    return history\n",
    "\n",
    "def evaluate_tf_model_with_embeddings(model, X_test, y_test):\n",
    "    y_pred = (model.predict([X_test[col] for col in X_test.columns]) > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return 1 - accuracy\n",
    "\n",
    "def cross_validate_tf_with_embeddings(X, y, model_params, n_folds=3):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    input_dims = [X[col].max() + 1 for col in X.columns]\n",
    "    for params in model_params:\n",
    "        val_errors = []\n",
    "        for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "            X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "            model = create_tf_model_with_embeddings(input_dims, **params)\n",
    "            history = train_tf_model_with_embeddings(model, X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
    "            val_error = evaluate_tf_model_with_embeddings(model, X_val_fold, y_val_fold)\n",
    "            val_errors.append(val_error)\n",
    "            print(f\"Fold: {fold}    Validation Error: {val_error*100:.2f}%\")\n",
    "        print(\"\\nMean(Std. Dev.) over all folds:\\n-------------------------------\")\n",
    "        print(f\"Validation Error: {np.mean(val_errors)*100:.2f}% ({np.std(val_errors)*100:.2f}%)\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "model_params = [\n",
    "    {'output_shape': 1, 'hidden_layers': 1, 'units_per_layer': 4}, \n",
    "    {'output_shape': 1, 'hidden_layers': 2, 'units_per_layer': 15},\n",
    "    {'output_shape': 1, 'hidden_layers': 3, 'units_per_layer': 36}\n",
    "]\n",
    "\n",
    "cross_validate_tf_with_embeddings(X_train, y_train, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0    Validation Error: 33.33%\n",
      "Fold: 1    Validation Error: 33.33%\n",
      "Fold: 2    Validation Error: 33.33%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Validation Error: 33.33% (0.00%)\n",
      "\n",
      "\n",
      "Fold: 0    Validation Error: 33.33%\n",
      "Fold: 1    Validation Error: 66.67%\n",
      "Fold: 2    Validation Error: 33.33%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Validation Error: 44.44% (15.71%)\n",
      "\n",
      "\n",
      "Fold: 0    Validation Error: 33.33%\n",
      "Fold: 1    Validation Error: 33.33%\n",
      "Fold: 2    Validation Error: 33.33%\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Validation Error: 33.33% (0.00%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# M3: MLPClassifier\n",
    "def cross_validate_sklearn(X, y, model_params, n_folds=3):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    for params in model_params:\n",
    "        val_errors = []\n",
    "        for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "            X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "            y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "            model = MLPClassifier(hidden_layer_sizes=(params['units_per_layer'],) * params['hidden_layers'],\n",
    "                                  activation='relu', solver='adam', random_state=42, max_iter=5000, \n",
    "                                  learning_rate_init=0.001)\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            val_preds = model.predict(X_val_fold)\n",
    "            val_error = 1 - accuracy_score(y_val_fold, val_preds)\n",
    "            val_errors.append(val_error)\n",
    "            print(f\"Fold: {fold}    Validation Error: {val_error*100:.2f}%\")\n",
    "        print(\"\\nMean(Std. Dev.) over all folds:\\n-------------------------------\")\n",
    "        print(f\"Validation Error: {np.mean(val_errors)*100:.2f}% ({np.std(val_errors)*100:.2f}%)\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "X_train_np = X_train.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "\n",
    "model_params = [\n",
    "    {'hidden_layers': 1, 'units_per_layer': 4}, \n",
    "    {'hidden_layers': 2, 'units_per_layer': 15},\n",
    "    {'hidden_layers': 3, 'units_per_layer': 36}\n",
    "]\n",
    "\n",
    "cross_validate_sklearn(X_train_np, y_train_np, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "1. Pytorch\n",
    "- Model Setup: Constructed using nn.Sequential with varying hidden layers and units per layer.\n",
    "- Training: Utilized Adam optimizer and BCELoss. Trained for 50 epochs per fold.\n",
    "- Cross-Validation: Used StratifiedKFold with 3 folds.\n",
    "- Pros and Cons: More hidden layers and units per layer lead to lower training error but higher validation error, suggesting overfitting.A model with one hidden layer and four units per layer maintained a more consistent performance across folds, indicating a better balance between training and validation errors.\n",
    "\n",
    "2. Tensorflow with Embedding\n",
    "- Model Setup: Created using embeddings for categorical features with varying hidden layers and units per layer.\n",
    "- Training: Utilized Adam optimizer and binary cross-entropy loss. Trained for 50 epochs per fold.\n",
    "- Cross-Validation: Used StratifiedKFold with 3 folds.\n",
    "- Pros and Cons: Similar to PyTorch, adding more hidden layers and units per layer reduces training error but increases validation error, suggesting overfitting. A model with one hidden layer and four units per layer performed more consistently, achieving a lower average validation error.\n",
    "\n",
    "3. MLPClassifier from scikit-learn\n",
    "- Model Setup: Configured using MLPClassifier with varying hidden layers and units per layer.\n",
    "- Training: Trained for a maximum of 5000 iterations per fold.\n",
    "- Cross-Validation: Used StratifiedKFold with 3 folds.\n",
    "- Pros and Cons: The model maintained consistent performance across all folds, showing no deviation in validation error. Although consistent, the model's flexibility and adaptability are limited.\n",
    "\n",
    "**Conclusion**:\n",
    "The PyTorch model was chosen as the winning model because it achieved the lowest average validation error(22.22%), indicating better performance in this comparison. Despite the higher standard deviation, its adaptability and potential for further tuning make it a more robust choice in the long run compared to the MLPClassifier, which is kind of limited. The TensorFlow model's higher average error made it less favorable despite its consistent performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
