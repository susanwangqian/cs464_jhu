{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence\n",
    "# 464/664\n",
    "# Assignment #6\n",
    "\n",
    "## General Directions for this Assignment\n",
    "\n",
    "00. We're using a Jupyter Notebook environment (tutorial available here: https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html),\n",
    "01. Read the entire notebook before beginning your work, \n",
    "02. Output format should be exactly as requested (it is your responsibility to make sure notebook looks as expected on Gradescope),\n",
    "03. Each helper function should be preceeded by documentation (Markdown cell), \n",
    "04. Each helper function (not `train`) should be followed by three assert-style unit tests,\n",
    "05. **Do not use any AI/ML libraries, packages, such as pandas, scikit (numpy is fine)**\n",
    "06. Functions should do only one thing,\n",
    "07. Check submission deadline on Gradescope, \n",
    "08. Rename the file to Last_First_assignment_6, \n",
    "09. Submit your notebook (as .ipynb, not PDF) using Gradescope, and\n",
    "10. Do not submit any other files.\n",
    "\n",
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For this assignment we will implement a Decision Tree using the ID3 Algorithm. The goal is classify a mushroom as either edible ('e') or poisonous ('p'). Dataset has been uploaded to Canvas. In case you'd like to learn more about it, here's the link to the repo: https://archive.ics.uci.edu/dataset/73/mushroom. \n",
    "\n",
    "\n",
    "Our  Decision Tree pipeline is as follows:\n",
    "\n",
    "\n",
    "1) `cross_validate` will take data (supplied as folds using 10 fold cross validation) and do the following:\n",
    "* For each setting of depth limit (the hyperparameter in decision trees, including 0)\n",
    "* * and for each fold of data\n",
    "* * * use `create_train_test` to split current fold into train and test\n",
    "* * * call `train` to build and return a decision tree, \n",
    "* * * call `classify` to use the tree to get classifications,\n",
    "* * * call `evaluate` to compare classifications to the actual answers (ground truth),\n",
    "* * * Print the performance for that fold\n",
    "* * Summarize the performance for that depth limit over all folds using `get_stats`\n",
    "\n",
    "\n",
    "2) `pretty_print_tree(tree)` will print what the tree looks like when using the **entire** data set (no train/test split) with depth limit set to None.\n",
    "\n",
    "\n",
    "All the code in this pipeline has been provided, except for a working `train` function. The `train` function currently returns a hard-coded tree from our lecture. Don't do that. Use ID3 to build your tree and use the depth limit to stop. When you're train function is complete, it should work for the lecture data, and mushrooms. Although `train` is terrible right now, pay attention to how the tree is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Tuple, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"note\"></a>\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Note</strong>\n",
    "    <p>\n",
    "        Let's start with our example from the 06-Nov lecture. Target variable is Safe?, which can be yes or no. Anything *_lecture refers to the dataset we walked through in class.  \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_lecture = [['round','large','blue','no'],\n",
    "['square','large','green','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','blue','no'],\n",
    "['round','small','blue','no'],\n",
    "['round','small','red','yes'],\n",
    "['square','small','green','no'],\n",
    "['round','large','green','yes'],\n",
    "['square','large','green','yes'],\n",
    "['square','large','red','no'],\n",
    "['square','large','green','yes'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','small','green','no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['round', 'large', 'blue', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(data_lecture[0]) # a record of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attribute_names_lecture = ['shape', \n",
    "                      'size', \n",
    "                      'color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_folds\"></a>\n",
    "## create_folds\n",
    "\n",
    "\n",
    "With n-fold cross validation, we divide our data set into n subgroups called \"folds\" and then use those folds for training and testing. For data set with 100 observations (or records), n set to 10 would have 10 observations in each fold.\n",
    "\n",
    "* **data** List: a list (data_lecture, for instance)\n",
    "* **n** int: number of folds\n",
    "\n",
    "\n",
    "**returns** \n",
    "folds, which is a list of n items, where each item is a list containing a subgroup of xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_folds(data: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(data), n)\n",
    "    return list(data[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds_lecture = create_folds(data=data_lecture, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(folds_lecture[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['square', 'small', 'red', 'no'], ['round', 'large', 'red', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(folds_lecture[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_train_test\"></a>\n",
    "## create_train_test\n",
    "\n",
    "\n",
    "This function takes the n folds and returns the train and test sets. One of the n folds is used to test, the others are used for training.\n",
    "\n",
    "* **folds** List[List[List]]: see `create_folds`\n",
    "* **index** int: fold index that is used for testing\n",
    "\n",
    "\n",
    "**returns** \n",
    "folds, which is a list of n items, where each item is a list containing a subgroup of xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lecture, test_lecture = create_train_test(folds_lecture, 0) # test data is folds_lecture index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['square', 'small', 'red', 'no'], ['round', 'large', 'red', 'yes'], ['square', 'small', 'blue', 'no'], ['round', 'small', 'blue', 'no'], ['round', 'small', 'red', 'yes'], ['square', 'small', 'green', 'no'], ['round', 'large', 'green', 'yes'], ['square', 'large', 'green', 'yes'], ['square', 'large', 'red', 'no'], ['square', 'large', 'green', 'yes'], ['round', 'large', 'red', 'yes'], ['square', 'small', 'red', 'no'], ['round', 'small', 'green', 'no']]\n"
     ]
    }
   ],
   "source": [
    "print(train_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(test_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lecture, test_lecture = create_train_test(folds_lecture, 1) # test data is folds_lecture index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['square', 'small', 'blue', 'no'], ['round', 'small', 'blue', 'no'], ['round', 'small', 'red', 'yes'], ['square', 'small', 'green', 'no'], ['round', 'large', 'green', 'yes'], ['square', 'large', 'green', 'yes'], ['square', 'large', 'red', 'no'], ['square', 'large', 'green', 'yes'], ['round', 'large', 'red', 'yes'], ['square', 'small', 'red', 'no'], ['round', 'small', 'green', 'no']]\n"
     ]
    }
   ],
   "source": [
    "print(train_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['square', 'small', 'red', 'no'], ['round', 'large', 'red', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(test_lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"note\"></a>\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <p>\n",
    "        Let's load the mushroom data.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"parse_data\"></a>\n",
    "## parse_data\n",
    "\n",
    "Opens a file, splits on comma, and shuffles data before returning as a List of list. \n",
    "\n",
    "* **file_name** Str: filename for data\n",
    "\n",
    "\n",
    "**returns** \n",
    "Data as a list of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [value for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mushroom = parse_data(\"agaricus-lepiota.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Important</strong>\n",
    "    <p>\n",
    "        We're going to move the target column (mushroom edible or poisonous) to the last column to match the lecture's format, where Safe? was at the end.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mushroom = [record[1:]+[record[0]] for record in data_mushroom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8124"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_mushroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'f', 'g', 'f', 'n', 'f', 'c', 'n', 'g', 'e', 'e', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'k', 'y', 'u', 'e']\n"
     ]
    }
   ],
   "source": [
    "print(data_mushroom[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names_mushroom = ['cap-shape',\n",
    "                   'cap-surface',\n",
    "                   'cap-color',\n",
    "                   'bruises?',\n",
    "                   'odor',\n",
    "                   'gill-attachment',\n",
    "                   'gill-spacing',\n",
    "                   'gill-size',\n",
    "                   'gill-color',\n",
    "                   'stalk-shape',\n",
    "                   'stalk-root',\n",
    "                   'stalk-surface-above-ring',\n",
    "                   'stalk-surface-below-ring',\n",
    "                   'stalk-color-above-ring',\n",
    "                   'stalk-color-below-ring',\n",
    "                   'veil-type',\n",
    "                   'veil-color',\n",
    "                   'ring-number',\n",
    "                   'ring-type',\n",
    "                   'spore-print-color',\n",
    "                   'population',\n",
    "                   'habitat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_answers\"></a>\n",
    "## get_answers\n",
    "\n",
    "This function extracts a list of the target values from data. The function assumes the target variable is the last column of the data.\n",
    "\n",
    "* **data** List[List]: The data provided in a list of list format identical to the structure of `data_lecture` or `data_mushroom`\n",
    "\n",
    "\n",
    "**returns** \n",
    "A list of the values of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(data):\n",
    "    return [record[-1] for record in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_answers([]) == []\n",
    "assert get_answers(data_lecture) == ['no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_mode\"></a>\n",
    "## get_mode\n",
    "\n",
    "This function finds the mode of a list of items. \n",
    "\n",
    "* **answers** List: A list of items\n",
    "\n",
    "**returns** \n",
    "The item that appears the most often in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(answers):\n",
    "    count_dict = {}\n",
    "    for answer in answers:\n",
    "        if answer in count_dict:\n",
    "            count_dict[answer] = count_dict[answer] + 1\n",
    "        else:\n",
    "            count_dict[answer] = 1\n",
    "    mode_count = max(count_dict.values())\n",
    "    mode = [k for k, v in count_dict.items() if v == mode_count]\n",
    "    return mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_mode(['no', 'no', 'no', 'yes']) == 'no'\n",
    "assert get_mode(['no', 'no', 'yes', 'yes']) == 'no'\n",
    "assert get_mode(['no', 'yes', 'yes', 'yes']) == 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"entropy\"></a>\n",
    "## entropy\n",
    "\n",
    "This function calculates the entropy of a dataset, using the entropy formula provided in lecture.\n",
    "\n",
    "* **data** List[List]: The data provided in a list of list format.\n",
    "\n",
    "**returns** \n",
    "A float representing the entropy of the dataset. Higher values indicate greater unpredictability or diversity in label values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    label_counts = {}\n",
    "    for label in get_answers(data):\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    total = len(data)\n",
    "    entropy = 0\n",
    "    for count in label_counts.values():\n",
    "        probability = count / total\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert entropy(['yes', 'yes', 'yes', 'yes']) == 0\n",
    "assert entropy(['yes', 'no', 'yes', 'no']) == 1.0\n",
    "assert abs(entropy(['yes', 'no', 'no', 'no']) - 0.811) < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"information_gain\"></a>\n",
    "## information_gain\n",
    "\n",
    "This function calculates the information gain for a specific attribute in a dataset.\n",
    "\n",
    "* **data** List[List]: The dataset provided as a list of lists, where each inner list represents a data record.\n",
    "* **attribute_index** int: The index of the attribute in the dataset based on which the dataset is split.\n",
    "\n",
    "**returns** \n",
    "A float representing the information gain for the specified attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(data, attribute_index):\n",
    "    total_entropy = entropy(data)\n",
    "    attribute_values = {}\n",
    "    for record in data:\n",
    "        attribute_value = record[attribute_index]\n",
    "        if attribute_value not in attribute_values:\n",
    "            attribute_values[attribute_value] = []\n",
    "        attribute_values[attribute_value].append(record)\n",
    "    weighted_entropy = 0\n",
    "    for subset in attribute_values.values():\n",
    "        weighted_entropy += (len(subset) / len(data)) * entropy(subset)\n",
    "    return total_entropy - weighted_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert information_gain([['yes'], ['yes'], ['yes'], ['yes']], 0) == 0\n",
    "assert information_gain([['yes', 'high'], ['no', 'low'], ['yes', 'low'], ['no', 'high']], 1) > 0\n",
    "assert information_gain([['rain', 'high'], ['sun', 'low'], ['cloudy', 'medium'], ['rain', 'medium']], 0) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"majority_class\"></a>\n",
    "## majority_class\n",
    "\n",
    "This function determines the majority class (the most frequently occurring class) in the dataset. It is particularly useful in classification tasks to establish a baseline or default prediction.\n",
    "\n",
    "* **data** List[List]: The dataset provided in a list of lists format. Each inner list represents a record, and the function focuses on the target variable in the last column of each record.\n",
    "\n",
    "**returns** \n",
    "The value of the target variable that appears most frequently in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(data):\n",
    "    answer = get_answers(data)\n",
    "    mode = get_mode(answer)\n",
    "    return mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert majority_class([['dog'], ['cat'], ['dog']]) == 'dog'\n",
    "assert majority_class([['apple'], ['apple'], ['banana'], ['banana'], ['banana']]) == 'banana'\n",
    "assert majority_class([['red'], ['blue'], ['red'], ['red'], ['blue'], ['blue'], ['red']]) == 'red'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pick_best_attribute\"></a>\n",
    "## pick_best_attribute\n",
    "\n",
    "This function identifies the best attribute for splitting the dataset based on the highest information gain.\n",
    "\n",
    "* **data** List[List]: The dataset provided in a list of lists format, where each inner list represents a record.\n",
    "* **attribute_names** List[str]: A list of attribute names corresponding to the columns of the data.\n",
    "\n",
    "**returns**\n",
    "A tuple containing:\n",
    "    1) The index of the best attribute for splitting the data.\n",
    "    2) A dictionary where the keys are the values of the best attribute and the values are the subsets of the dataset corresponding to each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_attribute(data, attribute_names):\n",
    "    best_gain = 0\n",
    "    best_attribute = None\n",
    "    best_partitions = {}\n",
    "    for attribute_index, attribute in enumerate(attribute_names):\n",
    "        gain = information_gain(data, attribute_index)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attribute = attribute_index\n",
    "            partitions = {}\n",
    "            for record in data:\n",
    "                key = record[attribute_index]\n",
    "                if key not in partitions:\n",
    "                    partitions[key] = []\n",
    "                partitions[key].append(record)\n",
    "            best_partitions = partitions\n",
    "    return best_attribute, best_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert pick_best_attribute([['yes', 'high'], ['no', 'low'], ['yes', 'medium'], ['no', 'high']], ['Decision', 'Level'])[0] == 1\n",
    "assert pick_best_attribute([['red', 'circle'], ['blue', 'square'], ['red', 'triangle'], ['blue', 'circle']], ['Color', 'Shape'])[0] == 1\n",
    "assert pick_best_attribute([['apple', 'sweet'], ['banana', 'sweet'], ['grape', 'sour'], ['banana', 'very sweet']], ['Fruit', 'Taste'])[0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"train\"></a>\n",
    "## train\n",
    "\n",
    "This function takes training_data, attribute names, and the depth limit and returns the decision tree as a nested dictionary. If the depth is 0, a dictionary is not returned. Instead, the mode of the target values is returned (i.e., majority class). \n",
    "\n",
    "* **training_data** List[List]: The data\n",
    "* **attribute_names** List: The attribute names of the data (22 for mushroom; size, shape, and color for the lecture)\n",
    "* **depth_limit** int: The depth limit of the tree\n",
    "\n",
    "\n",
    "**returns** \n",
    "* **dt** Dict: The trained decision tree using the ID3 algorithm (entropy, information gain). It is represented as a nested dictionary. The dictionary returned for the lecture is structured as below:\n",
    "\n",
    "```\n",
    "{\n",
    "('size', 1, 'large'): \n",
    "    {('color', 2, 'blue'): 'no', \n",
    "     ('color', 2, 'green'): 'yes', \n",
    "     ('color', 2, 'red'): \n",
    "         {('shape', 0, 'round'): 'yes', \n",
    "          ('shape', 0, 'square'): 'no'}\n",
    "     }, \n",
    "('size', 1, 'small'): \n",
    "     {('shape', 0, 'square'): 'no', \n",
    "      ('shape', 0, 'round'): \n",
    "          {('color', 2, 'blue'): 'no', \n",
    "           ('color', 2, 'red'): 'yes', \n",
    "           ('color', 2, 'green'): 'no'}\n",
    "      }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "Notice that the keys are tuples; for instance, ('size', 1, 'large') is a key. The key includes the attribute's name, column number in data, and value.\n",
    "\n",
    "\n",
    "The function currently returns a hard-coded tree. Your implementation should replace this with a tree that is learned from the data using the ID3 algorithm. You do not have to assert test `train`, but it may be worthwhile to check that it can return the tree from the lecture once your implementation is in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, attribute_names, depth_limit=None):\n",
    "    if not training_data:\n",
    "        return majority_class(training_data)\n",
    "    if all(record[-1] == training_data[0][-1] for record in training_data):\n",
    "        return training_data[0][-1]\n",
    "    if depth_limit == 0:\n",
    "        return majority_class(training_data)\n",
    "\n",
    "    best_attribute, best_partitions = pick_best_attribute(training_data, attribute_names)\n",
    "    if best_attribute is None:\n",
    "        return majority_class(training_data)\n",
    "    tree = {}\n",
    "    for attribute_value, subset in best_partitions.items():\n",
    "        if depth_limit is not None:\n",
    "            new_depth_limit = depth_limit - 1\n",
    "        else:\n",
    "            new_depth_limit = None\n",
    "        subtree = train(subset, attribute_names, new_depth_limit)\n",
    "        tree[(attribute_names[best_attribute], best_attribute, attribute_value)] = subtree\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_lecture = train(training_data=train_lecture, attribute_names=attribute_names_lecture, depth_limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_prediction\"></a>\n",
    "## get_prediction\n",
    "\n",
    "This recursive function uses a decision tree represented as a nested dictionary get a prediction from a record, which is a row of the data. \n",
    "\n",
    "* **record** List[]: A row of data to be predicted\n",
    "* **dt** the decision tree used to make the prediction\n",
    "\n",
    "\n",
    "**returns** \n",
    "A prediction ('yes' or 'no' for instance, from our Self Check example.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(record, dt):\n",
    "    if not isinstance(dt, dict):\n",
    "        return dt\n",
    "    else:\n",
    "        for key, value in dt.items():\n",
    "            if record[key[1]]==key[2]:\n",
    "                return get_prediction(record, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "no\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print(get_prediction(['round','large','blue','no'], dt=dt_lecture))\n",
    "print(get_prediction(['square','large','green','yes'], dt=dt_lecture))\n",
    "print(get_prediction(['square','small','red','no'], dt=dt_lecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classify\"></a>\n",
    "## classify\n",
    "\n",
    "This function takes a decision tree, observations, and a labeled flag to return a list of classifications. \n",
    "\n",
    "* **dt** Dict: The decision tree as a nested dictionary\n",
    "* **observation** List[List]: a list of items, where each item is a row of the data\n",
    "* **labeled** Bool: true for labeled data\n",
    "\n",
    "\n",
    "**returns** \n",
    "* **y_hat** List: A list of classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(dt, observations):\n",
    "    y_hat = []\n",
    "    for record in observations:\n",
    "        y_hat.append(get_prediction(record, dt))   \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(classify(dt=dt_lecture, observations=test_lecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate\"></a>\n",
    "## evaluate\n",
    "\n",
    "This function evaluates the performance of a classifier. It takes a data set (training set or test set) and the classification result (see [classify](#classify) above and calculates the classification error rate:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$ \n",
    "\n",
    "* **y_hat** List: A list of predictions\n",
    "* **observations** List[List]: Data to be predicted (typically training or test set)\n",
    "\n",
    "\n",
    "**returns** \n",
    "\n",
    "* **error_rate** float: The error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_hat, observations):\n",
    "    errors = 0\n",
    "    ground_truth = get_answers(observations)\n",
    "    for index in range(len(y_hat)):\n",
    "        if y_hat[index] != ground_truth[index]:\n",
    "            errors = errors + 1\n",
    "    return errors / (len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(classify(dt=dt_lecture, observations=data_lecture), observations=data_lecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_stats\"></a>\n",
    "## get_stats\n",
    "\n",
    "This function computes the mean and the standard deviation for a given list of observations. \n",
    "\n",
    "* **observations** List[float]: A list of observations\n",
    "\n",
    "\n",
    "**returns** (mean, standard deviation) Tuple[float,float]: tuple consisting of mean and the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(observations: List[float]) -> Tuple[float,float]:\n",
    "    mean = sum(observations) / len(observations)\n",
    "    variance = sum([(elem - mean)**2 for elem in observations]) / len(observations)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    return mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_stats([2, 4, 4, 4, 5, 5, 7, 9]) == (5.0, 2.0)\n",
    "assert get_stats([1, 1, 1]) == (1.0, 0.0)\n",
    "assert get_stats([0]) == (0.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cross_validate\"></a>\n",
    "## cross_validate\n",
    "\n",
    "This function takes folds of data to `train`, `classify`, and `evaluate`.\n",
    "\n",
    "\n",
    "* **folds** List[List[List]]: The original dataset partitioned into folds (see `create_folds` above)\n",
    "* **attribute_names** int: the feature names\n",
    "* **hyperparameters** List: A list of hyperparameters to explore (depth limits for a decision tree, for instance)\n",
    "\n",
    "**returns** \n",
    "\n",
    "Nothing is returned, but for each hyperparameter setting, the function prints out the fold number and the error rate for that fold. The mean and variance is printed across folds for each hyperparameter setting. The error rates are reported in terms of percents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(folds, attribute_names, hyperparameters):\n",
    "    for hyperparameter in hyperparameters:\n",
    "        train_error, test_error  = [], []\n",
    "        error_list_train, error_list_test = [], []\n",
    "        for fold_index in range(len(folds)):\n",
    "            training_data, test_data = create_train_test(folds, fold_index)\n",
    "            tree = train(training_data=training_data, attribute_names=attribute_names, depth_limit=hyperparameter)\n",
    "            y_hat_train = classify(tree, training_data)\n",
    "            y_hat_test = classify(tree, test_data)\n",
    "            error_rate_train = evaluate(y_hat_train, training_data)\n",
    "            error_rate_test = evaluate(y_hat_test, test_data)\n",
    "            error_list_train.append(error_rate_train)\n",
    "            error_list_test.append(error_rate_test)\n",
    "            print(f\"Fold: {fold_index}\\tTrain Error: {error_rate_train*100:.2f}%\\tTest Error: {error_rate_test*100:.2f}%\")\n",
    "        print(f\"***\")\n",
    "        print(f\"Depth limit: {hyperparameter}\")\n",
    "        print(f\"\\nMean(Std. Dev.) over all folds:\\n-------------------------------\")\n",
    "        print(f\"Train Error: {get_stats(error_list_train)[0]*100:.2f}%({get_stats(error_list_train)[1]*100:.2f}%) Test Error: {get_stats(error_list_test)[0]*100:.2f}%({get_stats(error_list_test)[1]*100:.2f}%)\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tTrain Error: 46.15%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 46.15%\tTest Error: 50.00%\n",
      "Fold: 2\tTrain Error: 46.15%\tTest Error: 100.00%\n",
      "Fold: 3\tTrain Error: 46.15%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 38.46%\tTest Error: 100.00%\n",
      "Fold: 5\tTrain Error: 50.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 42.86%\tTest Error: 100.00%\n",
      "Fold: 7\tTrain Error: 42.86%\tTest Error: 100.00%\n",
      "Fold: 8\tTrain Error: 50.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 50.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 0\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 45.88%(3.53%) Test Error: 55.00%(41.53%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 30.77%\tTest Error: 50.00%\n",
      "Fold: 2\tTrain Error: 23.08%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 23.08%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 14.29%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 21.43%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 21.43%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 28.57%\tTest Error: 100.00%\n",
      "Fold: 9\tTrain Error: 28.57%\tTest Error: 100.00%\n",
      "***\n",
      "Depth limit: 1\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 22.20%(5.59%) Test Error: 45.00%(41.53%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 7.69%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 15.38%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 7.14%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 14.29%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 14.29%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 2\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 8.96%(6.53%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 3\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 4\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 5\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: None\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validate(folds=folds_lecture, attribute_names=attribute_names_lecture, hyperparameters=[0, 1, 2, 3, 4, 5, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pretty_print_tree\"></a>\n",
    "## pretty_print_tree\n",
    "\n",
    "This function provides a text-based representation of a decision tree that is represented as a nested dictionary. \n",
    "\n",
    "* **dt** Dict: The decision tree as a nested dictionary\n",
    "* **tab_space** Int: How much to tab successive depth levels of the resulting tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tree(dt, tab_space):\n",
    "    for key, value in dt.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(\"  \" * tab_space + str(key[0]).upper() + \" - \" + str(key[2]) + \": \")\n",
    "            print(\"\\n\")\n",
    "            pretty_print_tree(value, tab_space+3)\n",
    "        else:\n",
    "            print(\"  \" * tab_space + str(key[0]).upper() + \" - \" + str(key[2]) + \" =====> \" + str(value))\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE - large: \n",
      "\n",
      "\n",
      "      COLOR - blue =====> no\n",
      "\n",
      "\n",
      "      COLOR - green =====> yes\n",
      "\n",
      "\n",
      "      COLOR - red: \n",
      "\n",
      "\n",
      "            SHAPE - round =====> yes\n",
      "\n",
      "\n",
      "            SHAPE - square =====> no\n",
      "\n",
      "\n",
      "SIZE - small: \n",
      "\n",
      "\n",
      "      SHAPE - square =====> no\n",
      "\n",
      "\n",
      "      SHAPE - round: \n",
      "\n",
      "\n",
      "            COLOR - blue =====> no\n",
      "\n",
      "\n",
      "            COLOR - red =====> yes\n",
      "\n",
      "\n",
      "            COLOR - green =====> no\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_lecture = train(training_data=data_lecture, attribute_names=attribute_names_lecture, depth_limit=None)\n",
    "pretty_print_tree(dt_lecture, tab_space=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <p>\n",
    "        Let's work on the mushroom data. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the Mushrooom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_mushroom = create_folds(data=data_mushroom, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tTrain Error: 48.45%\tTest Error: 46.00%\n",
      "Fold: 1\tTrain Error: 48.50%\tTest Error: 45.51%\n",
      "Fold: 2\tTrain Error: 48.26%\tTest Error: 47.72%\n",
      "Fold: 3\tTrain Error: 48.23%\tTest Error: 47.97%\n",
      "Fold: 4\tTrain Error: 48.15%\tTest Error: 48.65%\n",
      "Fold: 5\tTrain Error: 48.02%\tTest Error: 49.88%\n",
      "Fold: 6\tTrain Error: 47.99%\tTest Error: 50.12%\n",
      "Fold: 7\tTrain Error: 48.28%\tTest Error: 47.54%\n",
      "Fold: 8\tTrain Error: 48.19%\tTest Error: 48.28%\n",
      "Fold: 9\tTrain Error: 47.96%\tTest Error: 50.37%\n",
      "***\n",
      "Depth limit: 0\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 48.20%(0.17%) Test Error: 48.20%(1.56%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 1.52%\tTest Error: 1.11%\n",
      "Fold: 1\tTrain Error: 1.52%\tTest Error: 1.11%\n",
      "Fold: 2\tTrain Error: 1.45%\tTest Error: 1.72%\n",
      "Fold: 3\tTrain Error: 1.44%\tTest Error: 1.85%\n",
      "Fold: 4\tTrain Error: 1.57%\tTest Error: 0.62%\n",
      "Fold: 5\tTrain Error: 1.50%\tTest Error: 1.23%\n",
      "Fold: 6\tTrain Error: 1.45%\tTest Error: 1.72%\n",
      "Fold: 7\tTrain Error: 1.44%\tTest Error: 1.85%\n",
      "Fold: 8\tTrain Error: 1.50%\tTest Error: 1.23%\n",
      "Fold: 9\tTrain Error: 1.38%\tTest Error: 2.34%\n",
      "***\n",
      "Depth limit: 1\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 1.48%(0.05%) Test Error: 1.48%(0.48%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 1\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 2\tTrain Error: 0.59%\tTest Error: 0.62%\n",
      "Fold: 3\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 4\tTrain Error: 0.63%\tTest Error: 0.25%\n",
      "Fold: 5\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 6\tTrain Error: 0.56%\tTest Error: 0.86%\n",
      "Fold: 7\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 8\tTrain Error: 0.56%\tTest Error: 0.86%\n",
      "Fold: 9\tTrain Error: 0.56%\tTest Error: 0.86%\n",
      "***\n",
      "Depth limit: 2\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.59%(0.02%) Test Error: 0.59%(0.20%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 1\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 2\tTrain Error: 0.27%\tTest Error: 0.49%\n",
      "Fold: 3\tTrain Error: 0.29%\tTest Error: 0.37%\n",
      "Fold: 4\tTrain Error: 0.31%\tTest Error: 0.12%\n",
      "Fold: 5\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 6\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 7\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 8\tTrain Error: 0.29%\tTest Error: 0.37%\n",
      "Fold: 9\tTrain Error: 0.29%\tTest Error: 0.37%\n",
      "***\n",
      "Depth limit: 3\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.30%(0.01%) Test Error: 0.30%(0.10%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 4\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 0.00%(0.00%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 5\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 0.00%(0.00%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: None\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 0.00%(0.00%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validate(folds=folds_mushroom, attribute_names=attribute_names_mushroom, hyperparameters=[0, 1, 2, 3, 4, 5, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <p>\n",
    "        Let's work on the mushroom data. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the Mushroom Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODOR - n: \n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - k =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - r =====> p\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - n =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - w: \n",
      "\n",
      "\n",
      "            HABITAT - w =====> e\n",
      "\n",
      "\n",
      "            HABITAT - g =====> e\n",
      "\n",
      "\n",
      "            HABITAT - p =====> e\n",
      "\n",
      "\n",
      "            HABITAT - d: \n",
      "\n",
      "\n",
      "                  GILL-SIZE - n =====> p\n",
      "\n",
      "\n",
      "                  GILL-SIZE - b =====> e\n",
      "\n",
      "\n",
      "            HABITAT - l: \n",
      "\n",
      "\n",
      "                  CAP-COLOR - c =====> e\n",
      "\n",
      "\n",
      "                  CAP-COLOR - y =====> p\n",
      "\n",
      "\n",
      "                  CAP-COLOR - n =====> e\n",
      "\n",
      "\n",
      "                  CAP-COLOR - w =====> p\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - y =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - h =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - b =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - o =====> e\n",
      "\n",
      "\n",
      "ODOR - f =====> p\n",
      "\n",
      "\n",
      "ODOR - a =====> e\n",
      "\n",
      "\n",
      "ODOR - s =====> p\n",
      "\n",
      "\n",
      "ODOR - y =====> p\n",
      "\n",
      "\n",
      "ODOR - l =====> e\n",
      "\n",
      "\n",
      "ODOR - m =====> p\n",
      "\n",
      "\n",
      "ODOR - p =====> p\n",
      "\n",
      "\n",
      "ODOR - c =====> p\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mushroom = train(training_data=data_mushroom, attribute_names=attribute_names_mushroom, depth_limit=None)\n",
    "pretty_print_tree(dt_mushroom, tab_space=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
